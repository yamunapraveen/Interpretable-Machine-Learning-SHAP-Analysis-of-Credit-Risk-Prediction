{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0583b5f7",
   "metadata": {},
   "source": [
    "# Credit Risk SHAP Project - Notebook with model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cc8d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found credit_risk_dataset.csv in working directory.\n",
      "Loaded dataset shape: (32581, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>D</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>5500</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0    PERSONAL          D      35000          16.02            1   \n",
       "1   EDUCATION          B       1000          11.14            0   \n",
       "2     MEDICAL          C       5500          12.87            1   \n",
       "3     MEDICAL          C      35000          15.23            1   \n",
       "4     MEDICAL          C      35000          14.27            1   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                 0.59                         Y                           3  \n",
       "1                 0.10                         N                           2  \n",
       "2                 0.57                         N                           3  \n",
       "3                 0.53                         N                           2  \n",
       "4                 0.55                         Y                           4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure the dataset file is present in the notebook working directory.\n",
    "# This notebook assumes `credit_risk_dataset.csv` is included alongside the notebook in the ZIP.\n",
    "import os, shutil\n",
    "if not os.path.exists(\"credit_risk_dataset.csv\"):\n",
    "    # Try copying from a known path if available (may not be necessary when ZIP contains CSV)\n",
    "    src = '/mnt/data/credit_risk_dataset.csv'\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, \"credit_risk_dataset.csv\")\n",
    "        print(\"Copied dataset from\", src)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"credit_risk_dataset.csv not found in working dir or source path. Ensure the CSV is next to this notebook.\")\n",
    "else:\n",
    "    print(\"Found credit_risk_dataset.csv in working directory.\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac317d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: F:\\Datas\\AI_Course\\Yamuna\\Credit_Risk_SHAP_WithModels_Package\\submission_package\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, os, pickle\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    shap = None\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "OUT = Path(\"submission_package\")\n",
    "MODELS_DIR = OUT/\"models\"\n",
    "OUT.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "print(\"Output folder:\", OUT.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0683d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected target: loan_status\n",
      "Num numeric: 7 Num categorical: 4\n",
      "Preprocessed shape: (32581, 11)\n",
      "Train/test sizes: (26064, 11) (6517, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset, detect target and preprocess\n",
    "df = pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "common_targets = [\"default\",\"loan_default\",\"loan_status\",\"SeriousDlqin2yrs\",\"DEFAULT_PAYMENT_NEXT_MONTH\",\"is_default\",\"default_payment_next_month\",\"target\"]\n",
    "target_col = None\n",
    "for t in common_targets:\n",
    "    if t in df.columns:\n",
    "        target_col = t\n",
    "        break\n",
    "if target_col is None:\n",
    "    last_col = df.columns[-1]\n",
    "    uniq = df[last_col].dropna().unique()\n",
    "    if set(uniq).issubset({0,1}) or len(uniq) <= 5:\n",
    "        target_col = last_col\n",
    "    else:\n",
    "        target_col = last_col\n",
    "        print(\"Warning: target not auto-detected; using last column:\", target_col)\n",
    "\n",
    "print(\"Detected target:\", target_col)\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Drop ID-like columns\n",
    "id_cols = [c for c in X.columns if c.lower().startswith(\"id\")]\n",
    "if id_cols:\n",
    "    X = X.drop(columns=id_cols)\n",
    "    print(\"Dropped id columns:\", id_cols)\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print(\"Num numeric:\", len(num_cols), \"Num categorical:\", len(cat_cols))\n",
    "\n",
    "num_pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', StandardScaler())])\n",
    "cat_pipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('enc', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "preprocessor = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
    "\n",
    "X_pre = preprocessor.fit_transform(X)\n",
    "print(\"Preprocessed shape:\", X_pre.shape)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Train/test sizes:\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b40a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved RandomForest model. AUC: 0.9312978858785743\n",
      "Saved XGBoost model. AUC: 0.9498688077028719\n",
      "[LightGBM] [Info] Number of positive: 5686, number of negative: 20378\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 26064, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218155 -> initscore=-1.276449\n",
      "[LightGBM] [Info] Start training from score -1.276449\n",
      "Saved LightGBM model. AUC: 0.9478848433904892\n",
      "Models used and saved: ['RandomForest', 'XGBoost', 'LightGBM']\n"
     ]
    }
   ],
   "source": [
    "# Train three models (if libs present) and save model artifacts + record models used\n",
    "results = {}\n",
    "models_used = []\n",
    "\n",
    "# 1) RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_proba = rf.predict_proba(X_test)[:,1]\n",
    "y_pred = rf.predict(X_test)\n",
    "results['random_forest'] = {'auc': roc_auc_score(y_test, y_proba), 'accuracy': accuracy_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "# Save model\n",
    "with open(MODELS_DIR/'random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "models_used.append('RandomForest')\n",
    "\n",
    "print(\"Saved RandomForest model. AUC:\", results['random_forest']['auc'])\n",
    "\n",
    "# 2) XGBoost\n",
    "if xgb is not None:\n",
    "    xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    y_proba = xgb_clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "    results['xgboost'] = {'auc': roc_auc_score(y_test, y_proba), 'accuracy': accuracy_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "    with open(MODELS_DIR/'xgboost.pkl','wb') as f:\n",
    "        pickle.dump(xgb_clf, f)\n",
    "    models_used.append('XGBoost')\n",
    "    print(\"Saved XGBoost model. AUC:\", results['xgboost']['auc'])\n",
    "else:\n",
    "    print(\"XGBoost not installed - skipped\")\n",
    "\n",
    "# 3) LightGBM\n",
    "if lgb is not None:\n",
    "    lgb_clf = lgb.LGBMClassifier(random_state=42, n_jobs=-1)\n",
    "    lgb_clf.fit(X_train, y_train)\n",
    "    y_proba = lgb_clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = lgb_clf.predict(X_test)\n",
    "    results['lightgbm'] = {'auc': roc_auc_score(y_test, y_proba), 'accuracy': accuracy_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)}\n",
    "    with open(MODELS_DIR/'lightgbm.pkl','wb') as f:\n",
    "        pickle.dump(lgb_clf, f)\n",
    "    models_used.append('LightGBM')\n",
    "    print(\"Saved LightGBM model. AUC:\", results['lightgbm']['auc'])\n",
    "else:\n",
    "    print(\"LightGBM not installed - skipped\")\n",
    "\n",
    "# Save metrics and models_used file\n",
    "import json\n",
    "with open(OUT/'model_metrics.json','w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "pd.DataFrame(results).T.to_csv(OUT/'model_metrics.csv')\n",
    "\n",
    "with open(MODELS_DIR/'models_used.txt','w') as f:\n",
    "    for m in models_used:\n",
    "        f.write(m + \"\\\\n\")\n",
    "print(\"Models used and saved:\", models_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0559503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for SHAP: xgboost\n",
      "Saved SHAP global plots to submission_package/\n",
      "Saved local SHAP: tp\n",
      "Saved local SHAP: tn\n",
      "Saved local SHAP: fp\n"
     ]
    }
   ],
   "source": [
    "# SHAP analysis (global + 3 local cases) if shap is installed\n",
    "if shap is None:\n",
    "    print(\"SHAP not installed - skipping SHAP section\")\n",
    "else:\n",
    "    best_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
    "    best_model = None\n",
    "    if best_name == 'random_forest':\n",
    "        best_model = rf\n",
    "    elif best_name == 'xgboost' and xgb is not None:\n",
    "        best_model = xgb_clf\n",
    "    elif best_name == 'lightgbm' and lgb is not None:\n",
    "        best_model = lgb_clf\n",
    "    print(\"Best model for SHAP:\", best_name)\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(X_pre)\n",
    "        # Global plots\n",
    "        shap.summary_plot(shap_values, X_pre, show=False)\n",
    "        plt.tight_layout(); plt.savefig(OUT/'shap_summary.png', dpi=150); plt.clf()\n",
    "        shap.summary_plot(shap_values, X_pre, plot_type='bar', show=False)\n",
    "        plt.tight_layout(); plt.savefig(OUT/'shap_bar.png', dpi=150); plt.clf()\n",
    "        print(\"Saved SHAP global plots to submission_package/\")\n",
    "        # Local plots for TP, TN, FP if available\n",
    "        preds = (best_model.predict_proba(X_pre)[:,1] >= 0.5).astype(int)\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "        tp_idx = tn_idx = fp_idx = None\n",
    "        for i,(p,yt) in enumerate(zip(preds, y)):\n",
    "            if p==1 and yt==1 and tp_idx is None:\n",
    "                tp_idx = i\n",
    "            if p==0 and yt==0 and tn_idx is None:\n",
    "                tn_idx = i\n",
    "            if p==1 and yt==0 and fp_idx is None:\n",
    "                fp_idx = i\n",
    "        local = [('tp',tp_idx),('tn',tn_idx),('fp',fp_idx)]\n",
    "        for name, idx in local:\n",
    "            if idx is None: continue\n",
    "            try:\n",
    "                shap.plots._waterfall.waterfall_legacy(explainer.expected_value, shap_values[idx], show=False)\n",
    "                plt.tight_layout(); plt.savefig(OUT/f'shap_local_{name}.png', dpi=150); plt.clf()\n",
    "                print(\"Saved local SHAP:\", name)\n",
    "            except Exception as e:\n",
    "                print(\"Could not save local SHAP for\", name, e)\n",
    "    except Exception as e:\n",
    "        print(\"SHAP TreeExplainer failed or error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981edff5-f801-4cfb-9ffc-f46826b9c9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6c9df-9946-4ffd-b442-361176b84f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da91c8-6c7b-4a55-a702-5987cb0bb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
